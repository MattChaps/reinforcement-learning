@article{Kaelbling1996,
  doi = {10.1613/jair.301},
  url = {https://doi.org/10.1613/jair.301},
  year = {1996},
  month = may,
  publisher = {{AI} Access Foundation},
  volume = {4},
  pages = {237--285},
  author = {L. P. Kaelbling and M. L. Littman and A. W. Moore},
  title = {Reinforcement Learning:  A Survey},
  journal = {Journal of Artificial Intelligence Research}
}

@book{2010,
  doi = {10.1007/978-0-387-30164-8},
  url = {https://doi.org/10.1007/978-0-387-30164-8},
  year = {2010},
  publisher = {Springer {US}},
  editor = {Claude Sammut and Geoffrey I. Webb},
  title = {Encyclopedia of Machine Learning}
}

@article{DBLP:journals/corr/abs-1811-12560,
  author    = {Vincent Fran{\c{c}}ois{-}Lavet and
               Peter Henderson and
               Riashat Islam and
               Marc G. Bellemare and
               Joelle Pineau},
  title     = {An Introduction to Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1811.12560},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.12560},
  archivePrefix = {arXiv},
  eprint    = {1811.12560},
  timestamp = {Mon, 03 Dec 2018 07:50:28 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-12560.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.5555/2998828.2998976,
author = {Gordon, Geoffrey J.},
title = {Stable Fitted Reinforcement Learning},
year = {1995},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {We describe the reinforcement learning problem, motivate algorithms which seek an approximation to the Q function, and present new convergence results for two such algorithms.},
booktitle = {Proceedings of the 8th International Conference on Neural Information Processing Systems},
pages = {1052–1058},
numpages = {7},
location = {Denver, Colorado},
series = {NIPS'95}
}

@InProceedings{10.1007/11564096_32,
author="Riedmiller, Martin",
editor="Gama, Jo{\~a}o
and Camacho, Rui
and Brazdil, Pavel B.
and Jorge, Al{\'i}pio M{\'a}rio
and Torgo, Lu{\'i}s",
title="Neural Fitted Q Iteration -- First Experiences with a Data Efficient Neural Reinforcement Learning Method",
booktitle="Machine Learning: ECML 2005",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="317--328",
abstract="This paper introduces NFQ, an algorithm for efficient and effective training of a Q-value function represented by a multi-layer perceptron. Based on the principle of storing and reusing transition experiences, a model-free, neural network based Reinforcement Learning algorithm is proposed. The method is evaluated on three benchmark problems. It is shown empirically, that reasonably few interactions with the plant are needed to generate control policies of high quality.",
isbn="978-3-540-31692-3"
}

@article{Mnih2015,
  doi = {10.1038/nature14236},
  url = {https://doi.org/10.1038/nature14236},
  year = {2015},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {518},
  number = {7540},
  pages = {529--533},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin Riedmiller and Andreas K. Fidjeland and Georg Ostrovski and Stig Petersen and Charles Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
  title = {Human-level control through deep reinforcement learning},
  journal = {Nature}
}

@article{article,
author = {Konda, Vijay and Gao, Vijaymohan},
year = {2000},
month = {01},
pages = {},
title = {Actor-critic algorithms}
}

@article{DBLP:journals/corr/SchulmanLMJA15,
  author    = {John Schulman and
               Sergey Levine and
               Philipp Moritz and
               Michael I. Jordan and
               Pieter Abbeel},
  title     = {Trust Region Policy Optimization},
  journal   = {CoRR},
  volume    = {abs/1502.05477},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.05477},
  archivePrefix = {arXiv},
  eprint    = {1502.05477},
  timestamp = {Mon, 13 Aug 2018 16:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanLMJA15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/SchulmanWDRK17,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Watkins1992,
  doi = {10.1007/bf00992698},
  url = {https://doi.org/10.1007/bf00992698},
  year = {1992},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {8},
  number = {3-4},
  pages = {279--292},
  author = {Christopher J. C. H. Watkins and Peter Dayan},
  title = {Q-learning},
  journal = {Machine Learning}
}

@book{R-352-PR,
author="Bellman, Richard Ernest and Stuart E. Dreyfus",
title="Applied Dynamic Programming",
address="Santa Monica, CA",
year="1962",
doi="",
publisher="RAND Corporation"
}

@article{DBLP:journals/corr/WangFL15,
  author    = {Ziyu Wang and
               Nando de Freitas and
               Marc Lanctot},
  title     = {Dueling Network Architectures for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.06581},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06581},
  archivePrefix = {arXiv},
  eprint    = {1511.06581},
  timestamp = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WangFL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/HasseltGS15,
  author    = {Hado van Hasselt and
               Arthur Guez and
               David Silver},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  archivePrefix = {arXiv},
  eprint    = {1509.06461},
  timestamp = {Mon, 13 Aug 2018 16:47:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HasseltGS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1710-02298,
  author    = {Matteo Hessel and
               Joseph Modayil and
               Hado van Hasselt and
               Tom Schaul and
               Georg Ostrovski and
               Will Dabney and
               Daniel Horgan and
               Bilal Piot and
               Mohammad Gheshlaghi Azar and
               David Silver},
  title     = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1710.02298},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.02298},
  archivePrefix = {arXiv},
  eprint    = {1710.02298},
  timestamp = {Mon, 13 Aug 2018 16:48:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-02298.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/MnihKSGAWR13,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  archivePrefix = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Williams1992,
  doi = {10.1007/bf00992696},
  url = {https://doi.org/10.1007/bf00992696},
  year = {1992},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {8},
  number = {3-4},
  pages = {229--256},
  author = {Ronald J. Williams},
  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  journal = {Machine Learning}
}

@inproceedings{10.5555/3044805.3044850,
author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
title = {Deterministic Policy Gradient Algorithms},
year = {2014},
publisher = {JMLR.org},
abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counterparts in high-dimensional action spaces.},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {I–387–I–395},
location = {Beijing, China},
series = {ICML'14}
}

@misc{lillicrap2019continuous,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2019},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Konda2000,
author = {Konda, Vijay and Tsitsiklis, John},
year = {2001},
month = {04},
pages = {},
title = {Actor-Critic Algorithms},
volume = {42},
journal = {Society for Industrial and Applied Mathematics}
}

@misc{mnih2016asynchronous,
      title={Asynchronous Methods for Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
      year={2016},
      eprint={1602.01783},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{schulman2018highdimensional,
      title={High-Dimensional Continuous Control Using Generalized Advantage Estimation}, 
      author={John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
      year={2018},
      eprint={1506.02438},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{kullback1951information,
  title={On information and sufficiency},
  author={Kullback, Solomon and Leibler, Richard A},
  journal={The annals of mathematical statistics},
  volume={22},
  number={1},
  pages={79--86},
  year={1951},
  publisher={JSTOR}
}

@Article{bellemare13arcade,
    author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
    title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
    journal = {Journal of Artificial Intelligence Research},
    year = "2013",
    month = "jun",
    volume = "47",
    pages = "253--279",
}

@misc{girshick2015fast,
      title={Fast R-CNN}, 
      author={Ross Girshick},
      year={2015},
      eprint={1504.08083},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}