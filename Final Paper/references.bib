@article{Kaelbling1996,
  doi = {10.1613/jair.301},
  url = {https://doi.org/10.1613/jair.301},
  year = {1996},
  month = may,
  publisher = {{AI} Access Foundation},
  volume = {4},
  pages = {237--285},
  author = {L. P. Kaelbling and M. L. Littman and A. W. Moore},
  title = {Reinforcement Learning:  A Survey},
  journal = {Journal of Artificial Intelligence Research}
}

@book{2010,
  doi = {10.1007/978-0-387-30164-8},
  url = {https://doi.org/10.1007/978-0-387-30164-8},
  year = {2010},
  publisher = {Springer {US}},
  editor = {Claude Sammut and Geoffrey I. Webb},
  title = {Encyclopedia of Machine Learning}
}

@article{DBLP:journals/corr/abs-1811-12560,
  author    = {Vincent Fran{\c{c}}ois{-}Lavet and
               Peter Henderson and
               Riashat Islam and
               Marc G. Bellemare and
               Joelle Pineau},
  title     = {An Introduction to Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1811.12560},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.12560},
  archivePrefix = {arXiv},
  eprint    = {1811.12560},
  timestamp = {Mon, 03 Dec 2018 07:50:28 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-12560.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.5555/2998828.2998976,
author = {Gordon, Geoffrey J.},
title = {Stable Fitted Reinforcement Learning},
year = {1995},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {We describe the reinforcement learning problem, motivate algorithms which seek an approximation to the Q function, and present new convergence results for two such algorithms.},
booktitle = {Proceedings of the 8th International Conference on Neural Information Processing Systems},
pages = {1052â€“1058},
numpages = {7},
location = {Denver, Colorado},
series = {NIPS'95}
}

@InProceedings{10.1007/11564096_32,
author="Riedmiller, Martin",
editor="Gama, Jo{\~a}o
and Camacho, Rui
and Brazdil, Pavel B.
and Jorge, Al{\'i}pio M{\'a}rio
and Torgo, Lu{\'i}s",
title="Neural Fitted Q Iteration -- First Experiences with a Data Efficient Neural Reinforcement Learning Method",
booktitle="Machine Learning: ECML 2005",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="317--328",
abstract="This paper introduces NFQ, an algorithm for efficient and effective training of a Q-value function represented by a multi-layer perceptron. Based on the principle of storing and reusing transition experiences, a model-free, neural network based Reinforcement Learning algorithm is proposed. The method is evaluated on three benchmark problems. It is shown empirically, that reasonably few interactions with the plant are needed to generate control policies of high quality.",
isbn="978-3-540-31692-3"
}

@article{Mnih2015,
  doi = {10.1038/nature14236},
  url = {https://doi.org/10.1038/nature14236},
  year = {2015},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {518},
  number = {7540},
  pages = {529--533},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin Riedmiller and Andreas K. Fidjeland and Georg Ostrovski and Stig Petersen and Charles Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
  title = {Human-level control through deep reinforcement learning},
  journal = {Nature}
}

