## 1.1 Reinforcement Learning

- RL is learning what to do to maximise a numerical reward signal. The learner discovers which actions yield the most reward by trial-and-error. Actions may affect immediate reward and all subsequent rewards (delayed rewards).

- RL is a problem, a class of solution methods that work well on the problem, and the field that studies the problem and its solution methods.

- The RL problem is the optimal control of incompletely-known Markov decision processes. A method well suited to solving such problems is a reinforcement learning method.

- A challenge in RL is trade-off between exploration and exploitation. To obtain a lot of reward, a RL agent must prefer actions it has tried in the past and found to be effective in producing reward. But to discover such actions, it has to try actions not selected before. The agent has to _exploit_ what it has already experienced in order to obtain reward, but it also has to _explore_ to make better action selections in the future. Neither can be pursued exclusively without failing at the task.

- RL starts with complete, interactive, goal-seeking agent. All RL agents have explicit goals, can sense aspects of their environments, and can choose actions to influence their environments.
