## 1.2 Examples

- RL examples:

  - Chess player makes move. Choice informed by planning &mdash; anticipating replies and counterreplies &mdash; and by immediate, intuitive judgements of desirability of positions and moves.

  - Controller adjusts parameters of a machine's operation in real time.

  - Newborn learns to walk then run.

  - Preparing breakfast by accessing information about the state of your body that determines your nutritional needs, level of hunger, and food preferences.

- Examples involve _interaction_ between an active-decision making agent and its environment, within which agent seeks to achieve a _goal_ despite _uncertainty_ about its environment. The agentâ€™s actions are permitted to affect the future state of the environment, thereby affecting the actions and opportunities available to the agent at later times. Correct choice requires taking into account indirect, delayed consequences of actions, and thus may require foresight or planning.

- In examples the effects of actions cannot be fully predicted; agent monitors environment frequently and reacts appropriately.

  - E.g. watching milk pouring so it doesn't overflow or winning at Chess.

- Agent can use its experience to improve its performance over time. The knowledge the agent brings to the task at the start &mdash; either from previous experience or built in by design or evolution &mdash; influences what is useful or easy to learn, but interaction with the environment is essential for adjusting behaviour to exploit specific features of the task
