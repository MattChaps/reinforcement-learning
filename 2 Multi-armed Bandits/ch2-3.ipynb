{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch2-3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOWZIwgFB0TzycNDmTp301w"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"M-zZH573-agc","colab_type":"text"},"source":["## 2.3 The 10-armed Testbed\n","\n","To assess relative effectiveness of greedy and $\\epsilon$-greedy action-value methods, compare them numerically on test problems.\n","\n","Compare greedy method with two $\\epsilon$-greedy methods ($\\epsilon=0.01$ and $\\epsilon=0.1$).\n","\n","For Average Reward against Steps, greedy improved slightly faster in the beginning, but then leveled off at a lower level. The $\\epsilon$-greedy methods eventually performed better because they continued to explore.\n","\n","Advantage of $\\epsilon$-greedy over greedy methods depends on the task. For example, with noisier rewards it takes more exploration to find the optimal action, and $\\epsilon$-greedy methods should fare even better relative to the greedy method."]}]}