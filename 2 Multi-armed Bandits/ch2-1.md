## 2.1 A k-armed Bandit Problem

- Consider the learning problem:

  - faced repeatedly with choice among k different options;
  - after each choice receive numerical reward chosen from a stationary probability distribution that depends on the action you selected

- Objective is to maximise expected total reward over some number of time steps.

- This is original form of k-armed _bandit problem_, so named by analogy to a slot machine with k levers instead of one. Each action selection is like a play of one of the slot machine's levers, and rewards are payoffs for hitting jackpot. Through repeated action selections you are to maximise your winnings by concentrating your actions on the best levers.   

- Each of the k actions has an expected or mean reward given that that actions is selected -- _value_ of that action.

- Let action selected on time step _t_ as A<sub>t</sub>, and the corresponding reward as R<sub>t</sub>. The value then of an arbitrary action _a_, denoted q<sub>*</sub>(a), is the expected reward given that _a_ is selected:
